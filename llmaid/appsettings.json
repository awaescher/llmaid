{
	"Provider": "lmstudio", // ollama, openai, lmstudio, or openai-compatible
	"Uri": "http://localhost:1234/v1", // Ollama: http://localhost:11434, LM Studio: http://localhost:1234/v1, OpenAI: https://api.openai.com/v1
	"ApiKey": "", // not required for Ollama or LM Studio (leave empty or use any placeholder)
	"WriteResponseToConsole": true,
	"CooldownSeconds": 0 // Cooldown time in seconds after processing each file (prevents overheating)
}
